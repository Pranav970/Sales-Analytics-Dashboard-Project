import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Load the cleaned dataset
df = pd.read_csv('../data/cleaned_sales_data.csv')
df['order_date'] = pd.to_datetime(df['order_date'])

# Advanced Data Analysis Notebook

# 1. Descriptive Statistics
def generate_descriptive_stats(df):
    """
    Generate comprehensive descriptive statistics for numerical columns
    """
    print("Descriptive Statistics:")
    print(df[['revenue', 'quantity', 'profit_margin']].describe())
    
    # Skewness and Kurtosis
    print("\nSkewness:")
    print(df[['revenue', 'quantity', 'profit_margin']].skew())
    
    print("\nKurtosis:")
    print(df[['revenue', 'quantity', 'profit_margin']].kurtosis())

# 2. Time Series Analysis
def time_series_analysis(df):
    """
    Perform time series analysis of sales data
    """
    # Monthly sales aggregation
    monthly_sales = df.groupby(pd.Grouper(key='order_date', freq='M')).agg({
        'revenue': 'sum',
        'quantity': 'sum',
        'order_id': 'count'
    }).reset_index()
    
    # Plotting monthly trends
    plt.figure(figsize=(12, 6))
    plt.subplot(2, 1, 1)
    plt.plot(monthly_sales['order_date'], monthly_sales['revenue'], marker='o')
    plt.title('Monthly Revenue Trend')
    plt.xlabel('Date')
    plt.ylabel('Total Revenue')
    
    plt.subplot(2, 1, 2)
    plt.plot(monthly_sales['order_date'], monthly_sales['quantity'], marker='o', color='green')
    plt.title('Monthly Sales Volume')
    plt.xlabel('Date')
    plt.ylabel('Total Quantity Sold')
    
    plt.tight_layout()
    plt.show()
    
    return monthly_sales

# 3. Customer Segmentation
def customer_segmentation(df):
    """
    Advanced customer segmentation using RFM (Recency, Frequency, Monetary) analysis
    """
    # Calculate RFM metrics
    rfm_data = df.groupby('customer_id').agg({
        'order_date': lambda x: (df['order_date'].max() - x.max()).days,  # Recency
        'order_id': 'count',  # Frequency
        'revenue': 'sum'  # Monetary
    })
    
    rfm_data.columns = ['Recency', 'Frequency', 'Monetary']
    
    # Normalize RFM metrics
    rfm_normalized = (rfm_data - rfm_data.min()) / (rfm_data.max() - rfm_data.min())
    
    # K-means Clustering
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    
    # Scale the data
    scaler = StandardScaler()
    rfm_scaled = scaler.fit_transform(rfm_normalized)
    
    # Perform clustering
    kmeans = KMeans(n_clusters=4, random_state=42)
    rfm_data['Cluster'] = kmeans.fit_predict(rfm_scaled)
    
    # Visualize clusters
    plt.figure(figsize=(10, 6))
    scatter = plt.scatter(rfm_data['Monetary'], rfm_data['Frequency'], 
                          c=rfm_data['Cluster'], cmap='viridis')
    plt.title('Customer Segmentation')
    plt.xlabel('Total Revenue')
    plt.ylabel('Order Frequency')
    plt.colorbar(scatter, label='Customer Segment')
    plt.show()
    
    return rfm_data

# 4. Product Performance Analysis
def product_performance_analysis(df):
    """
    Detailed analysis of product performance
    """
    # Product category performance
    product_performance = df.groupby('product_category').agg({
        'revenue': ['sum', 'mean'],
        'quantity': ['sum', 'mean'],
        'profit_margin': 'mean'
    }).reset_index()
    
    # Visualization
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    product_performance['revenue']['sum'].plot(kind='bar')
    plt.title('Total Revenue by Product Category')
    plt.xlabel('Product Category')
    plt.ylabel('Total Revenue')
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    product_performance['profit_margin'].plot(kind='bar')
    plt.title('Average Profit Margin by Product Category')
    plt.xlabel('Product Category')
    plt.ylabel('Avg Profit Margin')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    return product_performance

# 5. Correlation and Statistical Analysis
def correlation_analysis(df):
    """
    Perform correlation analysis and statistical tests
    """
    # Correlation matrix
    correlation_matrix = df[['revenue', 'quantity', 'price', 'profit_margin']].corr()
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Correlation Heatmap')
    plt.show()
    
    # Hypothesis testing: Is there a significant difference in revenue across product categories?
    categories = df['product_category'].unique()
    category_revenues = [df[df['product_category'] == cat]['revenue'] for cat in categories]
    f_statistic, p_value = stats.f_oneway(*category_revenues)
    
    print("\nOne-way ANOVA Test for Revenue Across Product Categories:")
    print(f"F-statistic: {f_statistic}")
    print(f"p-value: {p_value}")
    
    # Interpret results
    if p_value < 0.05:
        print("There is a statistically significant difference in revenue across product categories.")
    else:
        print("No statistically significant difference in revenue across product categories.")

# 6. Predictive Analytics Preparation
def prepare_predictive_model(df):
    """
    Prepare data for potential predictive modeling
    """
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    
    # Feature engineering
    df['month'] = df['order_date'].dt.month
    df['day_of_week'] = df['order_date'].dt.dayofweek
    
    # Select features for prediction
    features = ['quantity', 'price', 'month', 'day_of_week']
    target = 'revenue'
    
    # One-hot encode categorical variables
    df_encoded = pd.get_dummies(df, columns=['product_category', 'customer_country'])
    
    # Prepare features and target
    X = df_encoded[features + [col for col in df_encoded.columns if col.startswith(('product_category_', 'customer_country_'))]]
    y = df_encoded[target]
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test

# Main Execution
def main():
    # 1. Descriptive Statistics
    generate_descriptive_stats(df)
    
    # 2. Time Series Analysis
    monthly_sales = time_series_analysis(df)
    
    # 3. Customer Segmentation
    customer_segments = customer_segmentation(df)
    
    # 4. Product Performance
    product_performance = product_performance_analysis(df)
    
    # 5. Correlation Analysis
    correlation_analysis(df)
    
    # 6. Prepare for Predictive Modeling
    X_train, X_test, y_train, y_test = prepare_predictive_model(df)
    
    print("\nAnalysis Complete. Data prepared for further modeling.")

# Run the main analysis
if __name__ == '__main__':
    main()
